import os
import sys
import hashlib
import shutil
import logging
import configparser
import subprocess
import fnmatch
import concurrent.futures
from pathlib import Path
from datetime import datetime
import requests

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
LOG_FILE = 'sync_log.txt'
CONFIG_FILE = 'config.ini'
HASH_ALGORITHM = hashlib.sha256
READ_BUFFER_SIZE = 65536

# --- –ò—Å–∫–ª—é—á–µ–Ω–∏—è ---
class SyncCancelledError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ, –≤—ã–∑—ã–≤–∞–µ–º–æ–µ, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–º–µ–Ω—è–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é."""
    pass

# --- –§—É–Ω–∫—Ü–∏–∏ ---
def setup_logging(gui_log_handler=None):
    handlers = [
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
    if gui_log_handler: handlers.append(gui_log_handler)
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=handlers, force=True)

def send_telegram_notification(message):
    config = configparser.ConfigParser()
    if not os.path.exists(CONFIG_FILE): logging.warning(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {CONFIG_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω."); return
    config.read(CONFIG_FILE, encoding='utf-8')
    if not config.has_section('telegram') or not config.getboolean('telegram', 'enabled', fallback=False): logging.info("–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram –æ—Ç–∫–ª—é—á–µ–Ω–∞."); return
    token = config.get('telegram', 'bot_token', fallback=None)
    chat_id = config.get('telegram', 'chat_id', fallback=None)
    if not token or not chat_id or token == 'YOUR_TELEGRAM_BOT_TOKEN': logging.warning("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–ª–∏ ID —á–∞—Ç–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã."); return
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    payload = {'chat_id': chat_id, 'text': message, 'parse_mode': 'Markdown'}
    try:
        response = requests.post(url, json=payload, timeout=10)
        response.raise_for_status()
        logging.info("–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.")
    except requests.exceptions.RequestException as e: logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram: {e}")

def ensure_path_is_ready(path_str, net_creds=None):
    if os.path.exists(path_str): logging.info(f"–ü—É—Ç—å '{path_str}' –¥–æ—Å—Ç—É–ø–µ–Ω."); return True
    logging.warning(f"–ü—É—Ç—å '{path_str}' –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—ã—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–∫ —Å–µ—Ç–µ–≤–æ–≥–æ –ø—É—Ç–∏...")
    if not path_str.startswith('\\\\'): logging.error(f"–ü—É—Ç—å '{path_str}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è UNC –ø—É—Ç–µ–º –∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."); return False
    if not net_creds or not net_creds.get('user') or not net_creds.get('password'): logging.error(f"–£—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—É—Ç–∏ '{path_str}' –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."); return False
    user, password = net_creds['user'], net_creds['password']
    logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ '{path_str}' —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º '{user}'...")
    try:
        if sys.platform == "win32":
            command = ['net', 'use', path_str, password, f'/user:{user}', '/persistent:no']
            subprocess.run(command, capture_output=True, text=True, check=True, encoding='cp866', creationflags=0x08000000) # CREATE_NO_WINDOW
            logging.info(f"–ö–æ–º–∞–Ω–¥–∞ 'net use' –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –¥–ª—è '{path_str}'."); return True
        else: logging.warning(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –¥–ª—è {sys.platform}."); return False
    except (subprocess.CalledProcessError, FileNotFoundError) as e: logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å —Å–µ—Ç–µ–≤–æ–π –¥–∏—Å–∫ '{path_str}': {e}"); return False

def calculate_file_hash(file_path):
    hasher = HASH_ALGORITHM()
    try:
        with open(file_path, 'rb') as f:
            while chunk := f.read(READ_BUFFER_SIZE): hasher.update(chunk)
        return hasher.hexdigest()
    except (IOError, PermissionError) as e: logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path}: {e}"); return None

def get_files_map(directory, exclude_patterns=None, stop_event=None, comparison_mode='accurate', use_parallel=False):
    files_map = {}
    root_path = Path(directory)
    logging.info(f"–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {directory} (–†–µ–∂–∏–º: {comparison_mode}, –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ: {use_parallel})")
    files_to_process = []
    for file_path in root_path.rglob('*'):
        if stop_event and stop_event.is_set(): raise SyncCancelledError("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        if file_path.is_file():
            if exclude_patterns and any(fnmatch.fnmatch(file_path.name, pattern) for pattern in exclude_patterns):
                logging.info(f"–ò–°–ö–õ–Æ–ß–ï–ù–ò–ï: –§–∞–π–ª '{file_path.name}' –ø–æ —à–∞–±–ª–æ–Ω—É."); continue
            try:
                stat = file_path.stat()
                files_to_process.append({'path': file_path, 'rel_path': file_path.relative_to(root_path), 'size': stat.st_size, 'mtime': stat.st_mtime})
            except FileNotFoundError: continue
    
    def process_file(file_info):
        if stop_event and stop_event.is_set(): return None
        if comparison_mode == 'hybrid': return file_info['rel_path'], (file_info['size'], file_info['mtime'], None)
        file_hash = calculate_file_hash(file_info['path'])
        return (file_info['rel_path'], file_hash) if file_hash else None

    if use_parallel:
        with concurrent.futures.ThreadPoolExecutor() as executor: results = executor.map(process_file, files_to_process)
    else:
        results = map(process_file, files_to_process)
    for result in results:
        if result: rel_path, data = result; files_map[rel_path] = data
    return files_map

def sync_folders(source_dir, dest_dir, no_overwrite, delete_removed, sync_empty_dirs=False, exclude_patterns=None, stop_event=None, comparison_mode='accurate', use_parallel=False, use_staging=False, use_trash=False, progress_callback=None):
    source_path = Path(source_dir); dest_path = Path(dest_dir)
    if not dest_path.exists(): dest_path.mkdir(parents=True, exist_ok=True)
    
    if progress_callback: progress_callback('overall', 0, 1, "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞...")
    source_files = get_files_map(source_dir, exclude_patterns, stop_event, comparison_mode, use_parallel)
    if progress_callback: progress_callback('overall', 0, 1, "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è...")
    dest_files = get_files_map(dest_dir, exclude_patterns, stop_event, comparison_mode, use_parallel)
    
    stats = {"copied": 0, "updated": 0, "skipped": 0, "deleted": 0, "trashed": 0, "errors": 0, "dirs_created": 0}

    trash_dir = None
    if use_trash and delete_removed:
        trash_dir = dest_path / ".sync_trash" / datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        trash_dir.mkdir(parents=True, exist_ok=True)

    if sync_empty_dirs:
        for dirpath, _, _ in os.walk(source_dir):
            if stop_event and stop_event.is_set(): raise SyncCancelledError("–ü—Ä–µ—Ä–≤–∞–Ω–æ –Ω–∞ —ç—Ç–∞–ø–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø–∞–ø–æ–∫.")
            relative_dir = Path(dirpath).relative_to(source_path); dest_dir_path = dest_path / relative_dir
            if not dest_dir_path.exists(): logging.info(f"–°–û–ó–î–ê–ù–ò–ï –î–ò–†–ï–ö–¢–û–†–ò–ò: {relative_dir}"); dest_dir_path.mkdir(); stats["dirs_created"] += 1

    total_files = len(source_files)
    for i, (rel_path, source_data) in enumerate(source_files.items()):
        if stop_event and stop_event.is_set(): raise SyncCancelledError("–ü—Ä–µ—Ä–≤–∞–Ω–æ –Ω–∞ —ç—Ç–∞–ø–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤.")
        if progress_callback: progress_callback('overall', i + 1, total_files, f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {rel_path}")

        dest_file_path = dest_path / rel_path; needs_update = False; reason = ""
        if rel_path not in dest_files: needs_update = True; reason = "–ö–û–ü–ò–†–û–í–ê–ù–ò–ï (–Ω–æ–≤—ã–π)"
        else:
            dest_data = dest_files[rel_path]
            if comparison_mode == 'hybrid':
                source_size, source_mtime, _ = source_data; dest_size, dest_mtime, _ = dest_data
                if source_size != dest_size or int(source_mtime) != int(dest_mtime):
                    source_hash = calculate_file_hash(source_path / rel_path)
                    if stop_event and stop_event.is_set(): raise SyncCancelledError("–ü—Ä–µ—Ä–≤–∞–Ω–æ –Ω–∞ —ç—Ç–∞–ø–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è.")
                    dest_hash = calculate_file_hash(dest_path / rel_path)
                    if source_hash != dest_hash: needs_update = True; reason = "–û–ë–ù–û–í–õ–ï–ù–ò–ï (–∏–∑–º–µ–Ω–µ–Ω)"
            elif source_data != dest_data: needs_update = True; reason = "–û–ë–ù–û–í–õ–ï–ù–ò–ï (–∏–∑–º–µ–Ω–µ–Ω)"
        
        if needs_update:
            if no_overwrite and rel_path in dest_files: logging.warning(f"–ü–†–û–ü–£–°–ö (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –æ—Ç–∫–ª—é—á–µ–Ω–∞): {rel_path}"); stats["skipped"] += 1
            else:
                logging.info(f"{reason}: {rel_path}")
                try:
                    target_path = dest_file_path.with_suffix(dest_file_path.suffix + '.tmp') if use_staging else dest_file_path
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path / rel_path, target_path)
                    if use_staging: os.rename(target_path, dest_file_path)
                    if "–û–ë–ù–û–í–õ–ï–ù–ò–ï" in reason: stats["updated"] += 1
                    else: stats["copied"] += 1
                except Exception as e: logging.error(f"–û—à–∏–±–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–æ–º {rel_path}: {e}"); stats["errors"] += 1

    if delete_removed:
        files_to_delete = [p for p in dest_files if p not in source_files]
        total_delete = len(files_to_delete)
        for i, rel_path in enumerate(files_to_delete):
            if stop_event and stop_event.is_set(): raise SyncCancelledError("–ü—Ä–µ—Ä–≤–∞–Ω–æ –Ω–∞ —ç—Ç–∞–ø–µ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤.")
            if progress_callback: progress_callback('overall', i + 1, total_delete, f"–£–¥–∞–ª–µ–Ω–∏–µ/–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ: {rel_path}")
            if use_trash:
                logging.info(f"–í –ö–û–†–ó–ò–ù–£: {rel_path}")
                try:
                    trash_file_path = trash_dir / rel_path
                    trash_file_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(dest_path / rel_path), str(trash_file_path)); stats["trashed"] += 1
                except Exception as e: logging.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –≤ –∫–æ—Ä–∑–∏–Ω—É —Ñ–∞–π–ª–∞ {rel_path}: {e}"); stats["errors"] += 1
            else:
                logging.info(f"–£–î–ê–õ–ï–ù–ò–ï: {rel_path}")
                try: (dest_path / rel_path).unlink(); stats["deleted"] += 1
                except Exception as e: logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {rel_path}: {e}"); stats["errors"] += 1
        for dirpath, _, _ in os.walk(dest_path, topdown=False):
            relative_dir = Path(dirpath).relative_to(dest_path)
            source_equivalent = source_path / relative_dir
            if not source_equivalent.exists() and not os.listdir(dirpath):
                if str(relative_dir) != '.':
                    try: logging.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {dirpath}"); os.rmdir(dirpath)
                    except OSError as e: logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ø—É—Å—Ç–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {dirpath}: {e}")
    return stats

def run_sync_session(source, destination, no_overwrite, delete_removed, sync_empty_dirs=False, exclude_patterns=None, source_creds=None, dest_creds=None, stop_event=None, comparison_mode='accurate', use_parallel=False, use_staging=False, use_trash=False, progress_callback=None):
    start_time = datetime.now()
    logging.info("="*50); logging.info("–ù–∞—á–∞–ª–æ —Å–µ–∞–Ω—Å–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"); logging.info(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source}"); logging.info(f"–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {destination}")
    logging.info(f"–ü–µ—Ä–µ–∑–∞–ø–∏—Å—å –æ—Ç–∫–ª—é—á–µ–Ω–∞: {'–î–∞' if no_overwrite else '–ù–µ—Ç'}"); logging.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤: {'–î–∞' if delete_removed else '–ù–µ—Ç'}")
    logging.info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫: {'–î–∞' if sync_empty_dirs else '–ù–µ—Ç'}"); logging.info(f"–ò—Å–∫–ª—é—á–µ–Ω–∏—è: {exclude_patterns if exclude_patterns else '–ù–µ—Ç'}")
    logging.info(f"–†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {comparison_mode}"); logging.info(f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {'–î–∞' if use_parallel else '–ù–µ—Ç'}")
    logging.info(f"–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ: {'–î–∞' if use_trash else '–ù–µ—Ç'}"); logging.info(f"–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ: {'–î–∞' if use_staging else '–ù–µ—Ç'}"); logging.info("="*50)
    try:
        if not ensure_path_is_ready(source, source_creds): raise ConnectionError(f"–ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {source}")
        if not ensure_path_is_ready(destination, dest_creds): raise ConnectionError(f"–¶–µ–ª–µ–≤–æ–π –ø—É—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {destination}")
        stats = sync_folders(source, destination, no_overwrite, delete_removed, sync_empty_dirs, exclude_patterns, stop_event, comparison_mode, use_parallel, use_staging, use_trash, progress_callback)
        duration = datetime.now() - start_time
        summary = (f"‚úÖ *–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!*\n\n*–ò—Å—Ç–æ—á–Ω–∏–∫:* `{source}`\n*–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:* `{destination}`\n"
                   f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: `{duration}`\n\n*–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n- –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤—ã—Ö: *{stats['copied']}*\n- –û–±–Ω–æ–≤–ª–µ–Ω–æ: *{stats['updated']}*\n"
                   f"- –ü—Ä–æ–ø—É—â–µ–Ω–æ: *{stats['skipped']}*\n- –£–¥–∞–ª–µ–Ω–æ (–Ω–∞–≤—Å–µ–≥–¥–∞): *{stats['deleted']}*\n- –£–¥–∞–ª–µ–Ω–æ (–≤ –∫–æ—Ä–∑–∏–Ω—É): *{stats['trashed']}*\n"
                   f"- –°–æ–∑–¥–∞–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: *{stats.get('dirs_created', 0)}*\n- –û—à–∏–±–∫–∏: *{stats['errors']}*")
        logging.info("\n" + summary.replace('*', '').replace('`', '')); send_telegram_notification(summary)
    except SyncCancelledError as e:
        duration = datetime.now() - start_time
        cancel_message = f"üü° *–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º!*\n\n–ü—Ä–æ—Ü–µ—Å—Å –±—ã–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å–ª–µ `{duration}`.\n–°–æ–æ–±—â–µ–Ω–∏–µ: `{e}`"
        logging.warning(cancel_message.replace('*', '').replace('`', '')); send_telegram_notification(cancel_message)
        raise e
    except Exception as e:
        duration = datetime.now() - start_time
        error_message = (f"‚ùå *–û–®–ò–ë–ö–ê –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–ò!*\n\n–ü—Ä–æ–∏–∑–æ—à–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: `{e}`\n"
                         f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ —Å–±–æ—è: `{duration}`\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –ª–æ–≥-—Ñ–∞–π–ª–µ: `{LOG_FILE}`")
        logging.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}", exc_info=True); send_telegram_notification(error_message)
        raise e